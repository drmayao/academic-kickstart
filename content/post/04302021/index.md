---
title: '2021 Undergraduate Research Conference @ Texas Tech'
subtitle: 'Undergraduate Students at MALab Present Real-time data monitoring System with Nanorobotics'
summary:
authors:
- Ram
- Bibek
tags:
- Brief
categories:
- News
date: "2021-04-02T00:00:00Z"
lastmod: "2019-04-17T00:00:00Z"
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Placement options: 1 = Full column width, 2 = Out-set, 3 = Screen-width
# Focal point options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight
image:
  placement: 1
  caption: 'Real-time data monitoring System with Nanorobotics'
  focal_point: "Smart"
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---
We recently presented our project on Real-time data monitoring System with Nanorobotics at 2021 [Undergraduate Research Conference](https://www.depts.ttu.edu/true/urc/index.php).

Natural disasters and technical failures are destroying thousands of buildings every year as per the statistics of 2020. Therefore, our team is approaching to effectively build a nano-robot, which minimizes the financial loss by monitoring the real-time situations of the affected area, therefore, suggesting a better response. A real-time monitoring application helps to sense and transmit the data to our main Graphical User Interface (GUI). Moreover, the artificial intelligence (AI) technique guides our nano-robot to perform the basic human operation that overcomes many risky limitations of human beings.

We are excited about the Mars rover launched by NASA to gather information about the Mars surface. Similarly, we use an infrared transceiver, Bluetooth module, cameras, and temperature sensor to collect images, videos, temperature, the distance of the obstacle using Raspberry pi interfaces and 40 GPIO (General Purpose Input Output) pins. The robot consists of a lithium polymer battery for powering the entire robot. Python is used to implement serial communication and transmit the temperature, ultrasonic and infrared sensor data obtained. We also utilized the microcontroller Arduino Mega to drive the L298N driver to direct the robot car. The car can be controlled by using an infrared remote inside the building and using Bluetooth communication for outdoor communication. An interactive Android app is developed to modify the state of the robot.

We are implementing the robot later with ROS (Robotic Operating System) and RGB-D (Red Green Blue-Depth) Camera to capture RGB-D images and apply various computer applications like Simultaneous localization and mapping. This implementation makes our robot more scalable for industry and research.

This project is supported by [The Center for Transformative Undergraduate Experiences (TrUE)](https://www.depts.ttu.edu/true/)
